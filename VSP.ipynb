{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## **üìå Route Optimization Project using Clustering and VSP Algorithms**  \n",
        "**Author:** Pedro Miguel Figueroa Dom√≠nguez  \n",
        "\n",
        "### **üìñ Introduction**  \n",
        "This project is designed to **optimize visit routes** to different geographical locations using **clustering algorithms and the Traveling Salesman Problem (TSP) solution**. The process consists of two main steps:  \n",
        "\n",
        "1. **Clustering Points:**  \n",
        "   - A clustering algorithm groups locations into clusters with a **maximum of 281 points** each.  \n",
        "   - These clusters are assigned to different **agents** to distribute the workload.  \n",
        "\n",
        "2. **Route Optimization (TSP):**  \n",
        "   - The **Nearest Neighbor Algorithm** is used to determine the optimal visiting order within each cluster.  \n",
        "   - The route is sorted based on the **shortest distance between points**.  \n",
        "\n",
        "### **‚öôÔ∏è Prerequisites**  \n",
        "Before running the notebook, install the required Python libraries:  \n",
        "\n",
        "```python\n",
        "!pip install pandas googlemaps ortools folium openpyxl\n",
        "pip install folium pandas numpy scikit-learn geopy\n",
        "```\n",
        "\n",
        "\n",
        "### **üåç Getting Coordinates (If Not Available in Your Data)**  \n",
        "If your dataset does not contain **latitude and longitude coordinates**, you can extract them using the **Google Maps API**.  \n",
        "\n",
        "#### **Steps to Obtain Coordinates**  \n",
        "\n",
        "1. **Download an Address Dataset (if needed)**  \n",
        "   - If you only have business names and addresses, your file should have structured address information.  \n",
        "   - Recommended format: CSV or Excel with columns like **Business Name, Address, City, Country**.  \n",
        "\n",
        "2. **Get a Google Maps API Key**  \n",
        "   - Go to [Google Cloud Console](https://console.cloud.google.com/)  \n",
        "   - Enable the **Geocoding API**  \n",
        "   - Generate an **API Key**  \n",
        "\n",
        "3. **Insert the API Key into the Code**  \n",
        "   - The script will use this API key to query Google Maps and retrieve latitude/longitude.  \n",
        "\n",
        "4. **Run the Script to Convert Addresses to Coordinates**  \n",
        "   - The code will process each address and store the coordinates for later use.  \n",
        "\n",
        "### **üöÄ How to Use This Project**  \n",
        "\n",
        "1. **Load the Data**  \n",
        "   - Ensure your dataset includes either **coordinates** or **addresses** (if you plan to extract them).  \n",
        "   - If missing coordinates, use the Google Maps API method to obtain them.  \n",
        "   - The script will automatically load and process the dataset into a **DataFrame**.  \n",
        "\n",
        "2. **Run the Route Optimization Algorithm**  \n",
        "   - The script will create clusters of **maximum 281 points** each.  \n",
        "   - It will then apply the **TSP algorithm** to determine the optimal visiting order.  \n",
        "\n",
        "3. **Generate the CSV File and Visualize the Route**  \n",
        "   - Enter the **agent number** to generate a **route table**.  \n",
        "   - The script will generate a CSV file with the optimized route.  \n",
        "   - A **map will be displayed**, showing the numbered points in the correct order.  \n",
        "\n",
        "### **üìå Key Features**  \n",
        "‚úî **Efficient clustering** to distribute locations into manageable groups.  \n",
        "‚úî **Route optimization** using the **Nearest Neighbor TSP algorithm**.  \n",
        "‚úî **Automatic CSV generation** with sorted visiting orders.  \n",
        "‚úî **Interactive map visualization** with numbered points.  \n",
        "‚úî **Automatic coordinate retrieval** if not available.  \n",
        "\n",
        "### **üéØ Expected Results**  \n",
        "- **A well-organized table** displaying the optimal visiting order.  \n",
        "- **An interactive map** showing points numbered in sequence.  \n",
        "- **A CSV file** with the ordered route for each agent.  \n",
        "\n",
        "### **üìä Excel File Structure**  \n",
        "The Excel file used in this project must have the following structure:\n",
        "\n",
        "- The **sheet** must be called `Sheet1`.  \n",
        "- The **columns** should start from the **2nd row** with these headers:\n",
        "\n",
        "|   | A              | B       | C   | D       | E          | F         |\n",
        "|---|----------------|---------|-----|---------|------------|-----------|\n",
        "| 1 |                |         |     |         |            |           |\n",
        "| 2 | **Nombre Comercial** | **Calle** | **No.** | **Sector** | **Municipio** | **Provincia** |\n",
        "| 3 | Example Name    | Example St. | 123 | Sector 1 | City 1     | Province 1 |\n",
        "| 4 | Example Name 2  | Another St. | 456 | Sector 2 | City 2     | Province 2 |\n",
        "| 5 | ...             | ...     | ... | ...     | ...        | ...       |\n",
        "\n",
        "- Data should start from **row 3**. The **columns** are as follows:\n",
        "  - **Nombre Comercial** (Business Name)  \n",
        "  - **Calle** (Street)  \n",
        "  - **No.** (Street Number)  \n",
        "  - **Sector** (Sector)  \n",
        "  - **Municipio** (City)  \n",
        "  - **Provincia** (Province)  \n",
        "\n",
        "---\n",
        "\n",
        "üí° **This project streamlines visit planning and route optimization, ensuring efficiency in travel.** üöÄ"
      ],
      "metadata": {
        "id": "wULk-mZSGjKm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installs"
      ],
      "metadata": {
        "id": "wF1GAC8pGjIw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xePty2qi_ay7",
        "outputId": "19b5bc1b-19ce-4f4a-a9df-16b3fe0a41e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Collecting googlemaps\n",
            "  Downloading googlemaps-4.10.0.tar.gz (33 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ortools\n",
            "  Downloading ortools-9.11.4210-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: folium in /usr/local/lib/python3.11/dist-packages (0.19.4)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.20.0 in /usr/local/lib/python3.11/dist-packages (from googlemaps) (2.32.3)\n",
            "Collecting absl-py>=2.0.0 (from ortools)\n",
            "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting protobuf<5.27,>=5.26.1 (from ortools)\n",
            "  Downloading protobuf-5.26.1-cp37-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Requirement already satisfied: immutabledict>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from ortools) (4.2.1)\n",
            "Requirement already satisfied: branca>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from folium) (0.8.1)\n",
            "Requirement already satisfied: jinja2>=2.9 in /usr/local/lib/python3.11/dist-packages (from folium) (3.1.5)\n",
            "Requirement already satisfied: xyzservices in /usr/local/lib/python3.11/dist-packages (from folium) (2025.1.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=2.9->folium) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.20.0->googlemaps) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.20.0->googlemaps) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.20.0->googlemaps) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.20.0->googlemaps) (2024.12.14)\n",
            "Downloading ortools-9.11.4210-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m28.1/28.1 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-5.26.1-cp37-abi3-manylinux2014_x86_64.whl (302 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m302.8/302.8 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: googlemaps\n",
            "  Building wheel for googlemaps (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googlemaps: filename=googlemaps-4.10.0-py3-none-any.whl size=40715 sha256=465f47336dfa22c4858308eb79d77256188bb047f6381d65dc06ab109bf2ca02\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/09/77/3cc2f5659cbc62341b30f806aca2b25e6a26c351daa5b1f49a\n",
            "Successfully built googlemaps\n",
            "Installing collected packages: protobuf, absl-py, googlemaps, ortools\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.6\n",
            "    Uninstalling protobuf-4.25.6:\n",
            "      Successfully uninstalled protobuf-4.25.6\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.4.0\n",
            "    Uninstalling absl-py-1.4.0:\n",
            "      Successfully uninstalled absl-py-1.4.0\n",
            "Successfully installed absl-py-2.1.0 googlemaps-4.10.0 ortools-9.11.4210 protobuf-5.26.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas googlemaps ortools folium openpyxl\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install folium geopy numpy scikit-learn"
      ],
      "metadata": {
        "id": "2g1utn4JLMoT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b55984ae-2a21-48b5-a007-29a385365dc6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: folium in /usr/local/lib/python3.11/dist-packages (0.19.4)\n",
            "Requirement already satisfied: geopy in /usr/local/lib/python3.11/dist-packages (2.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: branca>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from folium) (0.8.1)\n",
            "Requirement already satisfied: jinja2>=2.9 in /usr/local/lib/python3.11/dist-packages (from folium) (3.1.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from folium) (2.32.3)\n",
            "Requirement already satisfied: xyzservices in /usr/local/lib/python3.11/dist-packages (from folium) (2025.1.0)\n",
            "Requirement already satisfied: geographiclib<3,>=1.52 in /usr/local/lib/python3.11/dist-packages (from geopy) (2.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=2.9->folium) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->folium) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->folium) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->folium) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->folium) (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carga de datos"
      ],
      "metadata": {
        "id": "62GiWXQo8ZLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "# Subir archivo\n",
        "uploaded = files.upload()\n",
        "file_name = list(uploaded.keys())[0]\n",
        "df = pd.read_excel(file_name, sheet_name=\"Sheet1\",header=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "u8lNNtPSzV5j",
        "outputId": "54447eb3-0aa2-4509-f30c-e81be1c423a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7818425a-a296-4890-9751-76792b492aa2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7818425a-a296-4890-9751-76792b492aa2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "9a6gY61l0ALm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Limpieza de datos"
      ],
      "metadata": {
        "id": "Onwr3fA-8d8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns.tolist())"
      ],
      "metadata": {
        "id": "J9kt5-kP1Wd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "QiexPMs_0Rdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Crear columna 'Ubicacion' respetando NaNs originales\n",
        "columnas_a_combinar = [\n",
        "    \"Calle \",\n",
        "    \"No.\",\n",
        "    \"Sector \",\n",
        "    \"Municipio \",\n",
        "    \"Provincia \"\n",
        "]\n",
        "\n",
        "df[\"Ubicacion\"] = df[columnas_a_combinar].apply(\n",
        "    lambda row: ', '.join([str(val) for val in row if pd.notna(val)]),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Verificar resultado\n",
        "df[[\"Ubicacion\"] + columnas_a_combinar].head(10)"
      ],
      "metadata": {
        "id": "ElV6OMvcAKXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conseguir Coordenadas"
      ],
      "metadata": {
        "id": "jsbtXme38LN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import googlemaps\n",
        "import pandas as pd\n",
        "import time\n",
        "import logging\n",
        "import json\n",
        "from googlemaps.exceptions import ApiError, HTTPError, Timeout, TransportError\n",
        "\n",
        "# Configuraci√≥n inicial\n",
        "API_KEY = \"Introduce your API Keys\"\n",
        "gmaps = googlemaps.Client(key=API_KEY)\n",
        "\n",
        "# Configurar logging\n",
        "logging.basicConfig(\n",
        "    filename='geocoding.log',\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "\n",
        "# Par√°metros de ejecuci√≥n\n",
        "BATCH_SIZE = 50  # Tama√±o de lote para procesamiento\n",
        "DELAY = 2  # Segundos entre lotes\n",
        "MAX_RETRIES = 3  # Reintentos por fallo\n",
        "\n",
        "# Cargar cache si existe\n",
        "try:\n",
        "    with open('geocoding_cache.json', 'r') as f:\n",
        "        cache = json.load(f)\n",
        "except FileNotFoundError:\n",
        "    cache = {}\n",
        "\n",
        "def limpiar_nombres_columnas(df):\n",
        "    \"\"\"Elimina espacios adicionales en los nombres de las columnas\"\"\"\n",
        "    df.columns = df.columns.str.strip()\n",
        "    return df\n",
        "\n",
        "def limpiar_datos(df):\n",
        "    \"\"\"Preprocesamiento de datos cr√≠ticos\"\"\"\n",
        "    # Llenar valores esenciales y limpiar espacios\n",
        "    df['Provincia'] = df['Provincia'].fillna('').str.strip().str[:20]\n",
        "    df['Municipio'] = df['Municipio'].fillna('').str.strip().str[:20]\n",
        "    df['Calle'] = df['Calle'].fillna('').str.strip().str[:50]\n",
        "    return df\n",
        "\n",
        "def construir_direccion(row):\n",
        "    \"\"\"Construcci√≥n optimizada de direcci√≥n con componentes\"\"\"\n",
        "    componentes = {\n",
        "        'calle': f\"{row['Calle']} {row['No.']}\".strip() if pd.notna(row['No.']) else row['Calle'],\n",
        "        'sector': row['Sector'] if pd.notna(row['Sector']) else '',\n",
        "        'municipio': row['Municipio'],\n",
        "        'provincia': row['Provincia']\n",
        "    }\n",
        "\n",
        "    # Filtrar componentes vac√≠os\n",
        "    return {k: v for k, v in componentes.items() if v}\n",
        "\n",
        "def geocodificar_con_reintentos(componentes, intento=1):\n",
        "    \"\"\"L√≥gica de geocodificaci√≥n con reintentos inteligentes\"\"\"\n",
        "    try:\n",
        "        resultado = gmaps.geocode(\n",
        "            language='es',\n",
        "            components={\n",
        "                'route': componentes.get('calle', ''),\n",
        "                'sublocality': componentes.get('sector', ''),\n",
        "                'locality': componentes.get('municipio', ''),\n",
        "                'administrative_area': componentes.get('provincia', ''),\n",
        "                'country': 'DO'\n",
        "            }\n",
        "        )\n",
        "\n",
        "        if resultado:\n",
        "            loc = resultado[0]['geometry']['location']\n",
        "            if 17.4 < loc['lat'] < 19.9 and -72.0 < loc['lng'] < -68.3:\n",
        "                return loc['lat'], loc['lng']\n",
        "\n",
        "        # Fallback a municipio-provincia\n",
        "        if intento == 1 and componentes.get('municipio') and componentes.get('provincia'):\n",
        "            time.sleep(1)\n",
        "            return geocodificar_con_reintentos({\n",
        "                'municipio': componentes['municipio'],\n",
        "                'provincia': componentes['provincia']\n",
        "            }, intento=2)\n",
        "\n",
        "        return None, None\n",
        "\n",
        "    except (ApiError, HTTPError, Timeout, TransportError) as e:\n",
        "        if intento < MAX_RETRIES:\n",
        "            sleep_time = 2 ** intento\n",
        "            logging.warning(f\"Reintento {intento} en {sleep_time}s: {e}\")\n",
        "            time.sleep(sleep_time)\n",
        "            return geocodificar_con_reintentos(componentes, intento + 1)\n",
        "        logging.error(f\"Fallo definitivo: {e}\")\n",
        "        return None, None\n",
        "\n",
        "def geocodificar_con_cache(componentes):\n",
        "    \"\"\"Geocodificaci√≥n con cache para evitar solicitudes repetidas\"\"\"\n",
        "    clave_cache = json.dumps(componentes, sort_keys=True)\n",
        "    if clave_cache in cache:\n",
        "        return cache[clave_cache]\n",
        "\n",
        "    lat, lng = geocodificar_con_reintentos(componentes)\n",
        "    cache[clave_cache] = (lat, lng)\n",
        "\n",
        "    # Guardar cache actualizado\n",
        "    with open('geocoding_cache.json', 'w') as f:\n",
        "        json.dump(cache, f)\n",
        "\n",
        "    return lat, lng\n",
        "\n",
        "# Preprocesamiento\n",
        "df = limpiar_nombres_columnas(df)  # Corregir nombres de columnas\n",
        "df = limpiar_datos(df)  # Limpiar datos cr√≠ticos\n",
        "\n",
        "# Procesar solo direcciones √∫nicas\n",
        "direcciones_unicas = df[['Calle', 'No.', 'Sector', 'Municipio', 'Provincia']].drop_duplicates()\n",
        "coordenadas_unicas = {}\n",
        "\n",
        "for idx, row in direcciones_unicas.iterrows():\n",
        "    componentes = construir_direccion(row)\n",
        "    if not componentes.get('provincia') or not componentes.get('municipio'):\n",
        "        logging.warning(f\"Fila {idx}: Datos insuficientes\")\n",
        "        continue\n",
        "\n",
        "    coordenadas_unicas[json.dumps(componentes, sort_keys=True)] = geocodificar_con_cache(componentes)\n",
        "\n",
        "# Asignar coordenadas al DataFrame original\n",
        "def obtener_coordenadas(row):\n",
        "    componentes = construir_direccion(row)\n",
        "    clave = json.dumps(componentes, sort_keys=True)\n",
        "    return coordenadas_unicas.get(clave, (None, None))\n",
        "\n",
        "df[['Latitud', 'Longitud']] = df.apply(obtener_coordenadas, axis=1, result_type='expand')\n",
        "\n",
        "# Guardar resultados\n",
        "df.to_excel(\"direcciones_con_coordenadas_final.xlsx\", index=False)\n",
        "\n",
        "print(\"Proceso completado\")\n",
        "print(f\"√âxitos: {df[['Latitud', 'Longitud']].notnull().all(axis=1).sum()}\")\n",
        "print(f\"Fallos: {df[['Latitud', 'Longitud']].isnull().any(axis=1).sum()}\")"
      ],
      "metadata": {
        "id": "QRhiey82AThi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fallos = df[df['Latitud'].isnull() | df['Longitud'].isnull()]\n",
        "print(fallos[['Calle', 'No.', 'Sector', 'Municipio', 'Provincia']])"
      ],
      "metadata": {
        "id": "cZFhWEVo74vq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "5lV4PJuG7-Ye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predecir Rutas"
      ],
      "metadata": {
        "id": "Hj_OqKeA8Rjg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import numpy as np\n",
        "from geopy.distance import geodesic\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import pairwise_distances\n",
        "import folium\n",
        "from folium import plugins\n",
        "from IPython.display import display\n",
        "\n",
        "# --- FILTRADO Y PREPARACI√ìN DE DATOS ---\n",
        "valid_coords_mask = df[['Latitud', 'Longitud']].notnull().all(axis=1)\n",
        "valid_coords_df = df[valid_coords_mask].copy()\n",
        "coordenadas = np.array(list(zip(valid_coords_df[\"Latitud\"], valid_coords_df[\"Longitud\"])))\n",
        "\n",
        "# --- CLUSTERING CON K-MEANS ---\n",
        "num_clusters = 10  # Se desean 10 cl√∫steres en total\n",
        "kmeans = KMeans(n_clusters=num_clusters, n_init=10, random_state=42)\n",
        "labels = kmeans.fit_predict(coordenadas)\n",
        "centroids = kmeans.cluster_centers_\n",
        "\n",
        "# ====================== NUEVO: REBALANCEAR CL√öSTERES PARA QUE NINGUNO EXCEDA 281 PUNTOS ======================\n",
        "capacidad = 281  # M√°ximo de puntos por cl√∫ster\n",
        "\n",
        "# Crear diccionario: clave = n√∫mero de cl√∫ster, valor = lista de √≠ndices de puntos\n",
        "clusters_dict = {i: [] for i in range(num_clusters)}\n",
        "for idx, label in enumerate(labels):\n",
        "    clusters_dict[label].append(idx)\n",
        "\n",
        "# Iterar mientras se puedan hacer cambios\n",
        "cambios = True\n",
        "while cambios:\n",
        "    cambios = False\n",
        "    for cl in range(num_clusters):\n",
        "        if len(clusters_dict[cl]) > capacidad:\n",
        "            # Ordenar los puntos del cl√∫ster de mayor a menor distancia respecto al centroide\n",
        "            points_sorted = sorted(clusters_dict[cl],\n",
        "                                   key=lambda i: np.linalg.norm(coordenadas[i] - centroids[cl]),\n",
        "                                   reverse=True)\n",
        "            for point_idx in points_sorted:\n",
        "                if len(clusters_dict[cl]) <= capacidad:\n",
        "                    break\n",
        "                # Calcular las distancias del punto a todos los centroides\n",
        "                dists_to_all = np.linalg.norm(centroids - coordenadas[point_idx], axis=1)\n",
        "                candidatos = np.argsort(dists_to_all)\n",
        "                # Buscar el primer cl√∫ster candidato que no sea el actual y que tenga capacidad\n",
        "                for cand in candidatos:\n",
        "                    if cand != cl and len(clusters_dict[cand]) < capacidad:\n",
        "                        clusters_dict[cand].append(point_idx)\n",
        "                        clusters_dict[cl].remove(point_idx)\n",
        "                        cambios = True\n",
        "                        break\n",
        "\n",
        "# Reconstruir el vector de etiquetas a partir del diccionario rebalaceado\n",
        "new_labels = np.empty_like(labels)\n",
        "for cl in range(num_clusters):\n",
        "    for idx in clusters_dict[cl]:\n",
        "        new_labels[idx] = cl\n",
        "labels = new_labels\n",
        "# ===================================================================================================================\n",
        "\n",
        "# --- ALGORITMO GEN√âTICO OPTIMIZADO PARA TSP ---\n",
        "def tsp_genetico_optimizado(coordenadas, poblacion_size=30, generaciones=100, tasa_mutacion=0.1):\n",
        "    n = len(coordenadas)\n",
        "\n",
        "    # Si hay menos de 3 puntos, retornar la ruta trivial\n",
        "    if n < 3:\n",
        "        return list(range(n))\n",
        "\n",
        "    # Precalcular matriz de distancias (Euclideana aproximada en km)\n",
        "    dist_matrix = pairwise_distances(coordenadas) * 111  # 1¬∞ ‚âà 111 km\n",
        "    np.fill_diagonal(dist_matrix, 0)\n",
        "\n",
        "    def calcular_fitness(ruta):\n",
        "        distancia_total = np.sum(dist_matrix[ruta[:-1], ruta[1:]])\n",
        "        return 1 / distancia_total if distancia_total > 0 else 1e-6  # evitar divisi√≥n por cero\n",
        "\n",
        "    def generar_individuo():\n",
        "        return np.random.permutation(n).tolist()\n",
        "\n",
        "    poblacion = [generar_individuo() for _ in range(poblacion_size)]\n",
        "\n",
        "    for _ in range(generaciones):\n",
        "        # Selecci√≥n por torneo\n",
        "        padres = []\n",
        "        for _ in range(poblacion_size):\n",
        "            indices = np.random.choice(len(poblacion), 3, replace=False)\n",
        "            candidatos = [poblacion[i] for i in indices]\n",
        "            padres.append(max(candidatos, key=lambda x: calcular_fitness(x)))\n",
        "\n",
        "        # Cruzamiento OX\n",
        "        nueva_poblacion = []\n",
        "        for i in range(0, poblacion_size, 2):\n",
        "            p1, p2 = padres[i], padres[i+1]\n",
        "            punto_cruce = np.random.randint(1, n-1)\n",
        "            hijo = p1[:punto_cruce] + [g for g in p2 if g not in p1[:punto_cruce]]\n",
        "            nueva_poblacion.append(hijo)\n",
        "            nueva_poblacion.append(p2)\n",
        "\n",
        "        # Mutaci√≥n\n",
        "        for ind in nueva_poblacion:\n",
        "            if np.random.rand() < tasa_mutacion:\n",
        "                i, j = np.random.choice(n, 2, replace=False)\n",
        "                ind[i], ind[j] = ind[j], ind[i]\n",
        "\n",
        "    return max(poblacion, key=lambda x: calcular_fitness(x))\n",
        "\n",
        "# --- OPTIMIZAR RUTAS POR CL√öSTER ---\n",
        "rutas_optimas = []\n",
        "for cluster_id in range(num_clusters):\n",
        "    # Filtrar coordenadas del cl√∫ster seg√∫n las etiquetas rebalaceadas\n",
        "    mascara_cluster = (labels == cluster_id)\n",
        "    coords_cluster = coordenadas[mascara_cluster]\n",
        "\n",
        "    # Optimizar ruta solo si hay m√°s de 1 punto\n",
        "    if len(coords_cluster) > 1:\n",
        "        ruta_optimizada = tsp_genetico_optimizado(coords_cluster)\n",
        "        rutas_optimas.append(ruta_optimizada)\n",
        "    else:\n",
        "        rutas_optimas.append([])\n",
        "\n",
        "# --- VISUALIZACI√ìN ---\n",
        "# Configurar mapa centrado en Rep√∫blica Dominicana\n",
        "mapa = folium.Map(location=[18.47, -69.93], zoom_start=9)\n",
        "plugins.Fullscreen().add_to(mapa)\n",
        "\n",
        "# Paleta de colores para clusters\n",
        "colores = [\n",
        "    '#FF0000', '#0000FF', '#00FF00', '#FFA500', '#800080',\n",
        "    '#FFC0CB', '#008080', '#A52A2A', '#808000', '#00FFFF'\n",
        "]\n",
        "# Si se necesitan m√°s colores, se a√±aden\n",
        "if num_clusters > len(colores):\n",
        "    import random\n",
        "    while len(colores) < num_clusters:\n",
        "        colores.append(\"#\" + \"\".join([random.choice('0123456789ABCDEF') for _ in range(6)]))\n",
        "\n",
        "# A√±adir rutas al mapa\n",
        "for cluster_id, ruta in enumerate(rutas_optimas):\n",
        "    if len(ruta) < 2:\n",
        "        continue\n",
        "\n",
        "    # Obtener puntos del cl√∫ster\n",
        "    mascara_cluster = (labels == cluster_id)\n",
        "    coords_cluster = coordenadas[mascara_cluster]\n",
        "\n",
        "    # Crear l√≠nea de ruta\n",
        "    puntos_ruta = [coords_cluster[i] for i in ruta]\n",
        "    folium.PolyLine(\n",
        "        locations=puntos_ruta + [puntos_ruta[0]],\n",
        "        color=colores[cluster_id],\n",
        "        weight=2,\n",
        "        opacity=0.7,\n",
        "        tooltip=f'Agente {cluster_id+1} - {len(ruta)} puntos'\n",
        "    ).add_to(mapa)\n",
        "\n",
        "# Ajustar vista a todos los puntos\n",
        "mapa.fit_bounds([[coordenadas[:, 0].min(), coordenadas[:, 1].min()],\n",
        "                 [coordenadas[:, 0].max(), coordenadas[:, 1].max()]])\n",
        "\n",
        "# Mostrar mapa\n",
        "mapa.get_root().width = \"1000px\"\n",
        "mapa.get_root().height = \"700px\"\n",
        "display(mapa)\n",
        "\n",
        "# --- GENERACI√ìN DE TABLAS ---\n",
        "for cluster_id, ruta in enumerate(rutas_optimas):\n",
        "    if len(ruta) == 0:\n",
        "        continue\n",
        "\n",
        "    # Obtener √≠ndices originales\n",
        "    mascara_cluster = (labels == cluster_id)\n",
        "    df_cluster = valid_coords_df[mascara_cluster].iloc[ruta]\n",
        "\n",
        "    print(f\"\\n=== Ruta Agente {cluster_id+1} ({len(ruta)} puntos) ===\")\n",
        "    display(df_cluster[['Nombre Comercial', 'Latitud', 'Longitud']].head())\n"
      ],
      "metadata": {
        "id": "OHNXnFaaLQgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deploy"
      ],
      "metadata": {
        "id": "YcAICcgHE2io"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import folium\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from geopy.distance import geodesic\n",
        "\n",
        "# --------------------- FUNCI√ìN: ORDENAR POR DISTANCIA M√ÅS CERCANA ---------------------\n",
        "def ordenar_por_distancia(coords):\n",
        "    \"\"\"\n",
        "    Implementa el algoritmo de Vecino M√°s Cercano para encontrar la ruta √≥ptima.\n",
        "    \"\"\"\n",
        "    if len(coords) == 0:\n",
        "        return []\n",
        "\n",
        "    n = len(coords)\n",
        "    visitado = np.zeros(n, dtype=bool)\n",
        "    ruta = [0]  # Empezamos desde el primer punto\n",
        "    visitado[0] = True\n",
        "\n",
        "    for _ in range(n - 1):\n",
        "        ult_punto = coords[ruta[-1]]\n",
        "        distancias = [\n",
        "            geodesic(ult_punto, coords[i]).kilometers if not visitado[i] else np.inf\n",
        "            for i in range(n)\n",
        "        ]\n",
        "        siguiente = np.argmin(distancias)\n",
        "        ruta.append(siguiente)\n",
        "        visitado[siguiente] = True\n",
        "\n",
        "    return ruta\n",
        "\n",
        "# --------------------- BLOQUE: EXTRAER RUTA PARA UN AGENTE Y MOSTRAR MAPA ---------------------\n",
        "# Solicitar el n√∫mero del agente (entre 1 y 10)\n",
        "agent_number = int(input(\"Ingrese el n√∫mero del agente (1 a 10): \"))\n",
        "cluster_id = agent_number - 1\n",
        "\n",
        "# Filtrar los puntos correspondientes al cl√∫ster del agente\n",
        "mask = (labels == cluster_id)\n",
        "if mask.sum() == 0:\n",
        "    print(f\"No hay puntos asignados para el agente {agent_number}.\")\n",
        "else:\n",
        "    # Extraer la tabla del cl√∫ster\n",
        "    df_cluster = valid_coords_df[mask].copy()\n",
        "\n",
        "    # Extraer las coordenadas\n",
        "    coords_cluster = coordenadas[mask]\n",
        "\n",
        "    # Ordenar la ruta por distancia m√°s cercana\n",
        "    ruta_ordenada = ordenar_por_distancia(coords_cluster)\n",
        "\n",
        "    # Aplicar el orden a la tabla\n",
        "    df_ruta = df_cluster.iloc[ruta_ordenada].copy()\n",
        "    df_ruta.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    # Agregar una columna \"Orden\" para indicar el n√∫mero de visita\n",
        "    df_ruta[\"Orden\"] = df_ruta.index + 1\n",
        "\n",
        "    # Mostrar la tabla ordenada\n",
        "    display(df_ruta[['Orden', 'Nombre Comercial', 'Latitud', 'Longitud']])\n",
        "\n",
        "    # Exportar la tabla a CSV\n",
        "    csv_filename = f\"ruta_agente_{agent_number}.csv\"\n",
        "    df_ruta.to_csv(csv_filename, index=False)\n",
        "    print(f\"CSV generado: {csv_filename}\")\n",
        "\n",
        "    # Crear un mapa centrado en el primer punto de la ruta\n",
        "    m = folium.Map(location=[coords_cluster[0][0], coords_cluster[0][1]], zoom_start=12)\n",
        "\n",
        "    # Color √∫nico para los puntos del agente\n",
        "    color_ruta = \"blue\"  # Puedes cambiar el color aqu√≠\n",
        "\n",
        "    # Agregar marcadores numerados con el mismo color\n",
        "    for i, (lat, lon) in enumerate(df_ruta[['Latitud', 'Longitud']].values):\n",
        "        folium.Marker(\n",
        "            location=[lat, lon],\n",
        "            icon=folium.Icon(color=color_ruta, icon=\"info-sign\"),\n",
        "            popup=f\"Orden {i+1}: {df_ruta.iloc[i]['Nombre Comercial']}\"\n",
        "        ).add_to(m)\n",
        "\n",
        "    # Mostrar el mapa\n",
        "    display(m)\n"
      ],
      "metadata": {
        "id": "1PS4yy5QEiK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AERn9gMGE6G_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}